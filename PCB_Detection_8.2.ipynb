{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/7pupuwen/PCB_QDETECTION/blob/main/PCB_Detection_8.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X68hOa5RsQgo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5c90983-7640-4ad0-ad2a-82bd7ef876ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/cli.py\", line 68, in main\n",
            "    out = args.func(**command_args)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/api/kaggle_api_extended.py\", line 1734, in dataset_download_cli\n",
            "    with self.build_kaggle_client() as kaggle:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/kaggle/api/kaggle_api_extended.py\", line 688, in build_kaggle_client\n",
            "    username=self.config_values['username'],\n",
            "             ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
            "KeyError: 'username'\n",
            "unzip:  cannot find or open pcb-defect-dataset.zip, pcb-defect-dataset.zip.zip or pcb-defect-dataset.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d norbertelter/pcb-defect-dataset -q\n",
        "!unzip -q pcb-defect-dataset.zip -d pcb_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pennylane -q"
      ],
      "metadata": {
        "id": "obM8w9kTsVMW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a499e4d-23f6-44db-e829-37cc1fb4cb34"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Set the label files\n",
        "train_labels_path = \"/content/pcb_data/pcb-defect-dataset/train/labels\"\n",
        "val_labels_path = \"/content/pcb_data/pcb-defect-dataset/val/labels\"\n",
        "test_labels_path = \"/content/pcb_data/pcb-defect-dataset/test/labels\"\n",
        "\n",
        "# Definition of convert label to csv\n",
        "def convert_labels_to_csv(labels_path, output_csv):\n",
        "    data = []\n",
        "\n",
        "    # read every .txt file\n",
        "    for file in os.listdir(labels_path):\n",
        "        if file.endswith(\".txt\"):\n",
        "            file_path = os.path.join(labels_path, file)\n",
        "            image_name = file.replace(\".txt\", \".jpg\")  # The file name corresponding to the image\n",
        "            with open(file_path, \"r\") as f:\n",
        "                lines = f.readlines()  #A .txt may have multiple lines of tags\n",
        "\n",
        "                for line in lines:\n",
        "                    values = line.strip().split()\n",
        "                    class_id = int(values[0])  # Defect category\n",
        "                    x_center, y_center, width, height = map(float, values[1:])  # Analyze numerical values\n",
        "\n",
        "                    # Save to DataFrame\n",
        "                    data.append([image_name, class_id, x_center, y_center, width, height])\n",
        "\n",
        "    # create DataFrame\n",
        "    df = pd.DataFrame(data, columns=[\"image_name\", \"class_id\", \"x_center\", \"y_center\", \"width\", \"height\"])\n",
        "\n",
        "    # Save as CSV\n",
        "    df.to_csv(output_csv, index=False)\n",
        "\n",
        "    print(f\"{output_csv} convert finish！\")\n",
        "    print(df.head(10))  # show the first 10 data\n",
        "\n",
        "# covert `train`、`val`、`test` labels\n",
        "convert_labels_to_csv(train_labels_path, \"train_labels.csv\")\n",
        "convert_labels_to_csv(val_labels_path, \"val_labels.csv\")\n",
        "convert_labels_to_csv(test_labels_path, \"test_labels.csv\")"
      ],
      "metadata": {
        "id": "_Q70o3GnsXKh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "b01982f3-f1ac-450d-cab7-a072139ac067"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/pcb_data/pcb-defect-dataset/train/labels'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6472a3160dc0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# covert `train`、`val`、`test` labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mconvert_labels_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train_labels.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mconvert_labels_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_labels_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val_labels.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mconvert_labels_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test_labels.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-6472a3160dc0>\u001b[0m in \u001b[0;36mconvert_labels_to_csv\u001b[0;34m(labels_path, output_csv)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# read every .txt file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/pcb_data/pcb-defect-dataset/train/labels'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#Set up image folder\n",
        "train_images_path = \"/content/pcb_data/pcb-defect-dataset/train/images\"\n",
        "val_images_path = \"/content/pcb_data/pcb-defect-dataset/val/images\"\n",
        "test_images_path = \"/content/pcb_data/pcb-defect-dataset/test/images\"\n",
        "\n",
        "# Read tag CSV\n",
        "train_labels_csv = \"train_labels.csv\"\n",
        "val_labels_csv = \"val_labels.csv\"\n",
        "test_labels_csv = \"test_labels.csv\"\n",
        "\n",
        "# Define functions to read images and match tags\n",
        "def load_images_and_labels(images_path, labels_csv):\n",
        "    df = pd.read_csv(labels_csv)  # Read CSV\n",
        "    X, y = [], []  # Store images and labels\n",
        "\n",
        "    # Read images and match tags\n",
        "    for _, row in df.iterrows():\n",
        "        img_path = os.path.join(images_path, row[\"image_name\"])\n",
        "\n",
        "        if os.path.exists(img_path):\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Convert to grayscale\n",
        "            img = cv2.resize(img, (64, 64)) / 255.0  # standardization\n",
        "            X.append(img)\n",
        "            y.append(row[\"class_id\"])  # Take only defect categories as labels\n",
        "\n",
        "    # NumPy array\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    print(f\"{labels_csv} processed, image data size: {X.shape}, label data size: {y.shape}\")\n",
        "    return X, y\n",
        "\n",
        "# read `train`、`val`、`test` data\n",
        "X_train, y_train = load_images_and_labels(train_images_path, train_labels_csv)\n",
        "X_val, y_val = load_images_and_labels(val_images_path, val_labels_csv)\n",
        "X_test, y_test = load_images_and_labels(test_images_path, test_labels_csv)"
      ],
      "metadata": {
        "id": "-gA_Gh4asuF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# take 500 data\n",
        "X_train, _, y_train, _ = train_test_split(X_train, y_train, train_size=1500, random_state=42, stratify=y_train)\n",
        "X_val, _, y_val, _ = train_test_split(X_val, y_val, train_size=1000, random_state=42, stratify=y_val)\n",
        "X_test, _, y_test, _ = train_test_split(X_test, y_test, train_size=1000, random_state=42, stratify=y_test)\n",
        "\n",
        "# Confirm data shape\n",
        "print(\"取樣後的影像數據 (Train):\", X_train.shape)  # (500, 64, 64)\n",
        "print(\"取樣後的標籤數據 (Train):\", y_train.shape)  # (500,)\n",
        "\n",
        "print(\"取樣後的影像數據 (Val):\", X_val.shape)  # (500, 64, 64)\n",
        "print(\"取樣後的標籤數據 (Val):\", y_val.shape)  # (500,)\n",
        "\n",
        "print(\"取樣後的影像數據 (Test):\", X_test.shape)  # (500, 64, 64)\n",
        "print(\"取樣後的標籤數據 (Test):\", y_test.shape)  # (500,)\n"
      ],
      "metadata": {
        "id": "QZp8JU4vwlu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "\n",
        "# Set up the quantum computer simulator (4 qubits, corresponding to 2x2 patch)\n",
        "n_qubits = 4\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def quantum_kernel(x):\n",
        "    \"\"\"\n",
        "    This is a quantum circuit that converts image patches into quantum features\n",
        "    \"\"\"\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(x[i] * np.pi, wires=i)  # Embedding image data using Ry gates\n",
        "        qml.Hadamard(wires=i)  # Join Hadamard Gate\n",
        "\n",
        "    # oin Quantum Entanglement\n",
        "    for i in range(n_qubits - 1):\n",
        "        qml.CNOT(wires=[i, i+1])\n",
        "\n",
        "    return qml.expval(qml.PauliZ(0))  # Output quantum features\n",
        "\n",
        "x_test = np.random.rand(4)  # 產生 4 個隨機數\n",
        "qml.draw_mpl(quantum_kernel)(x_test)"
      ],
      "metadata": {
        "id": "7wxBGd0YwrXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def quanvolution(image):\n",
        "    output_size = (image.shape[0] //2, image.shape[1] //2)\n",
        "    q_image = np.zeros(output_size)\n",
        "\n",
        "    for i in range(0, image.shape[0], 2):\n",
        "        for j in range(0, image.shape[1], 2):\n",
        "          patch = image[i:i+2, j:j+2].flatten()\n",
        "          q_image[i//2, j//2] = quantum_kernel(patch)\n",
        "\n",
        "    return q_image.flatten()"
      ],
      "metadata": {
        "id": "HUgTzit7wxCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do Quanvolution to data\n",
        "# X_train_quanv = np.array([quanvolution(img) for img in X_train])\n",
        "# X_val_quanv = np.array([quanvolution(img) for img in X_val])\n",
        "# X_test_quanv = np.array([quanvolution(img) for img in X_test])\n",
        "\n",
        "# print(\"Quantum feature size（Train）:\", X_train_quanv.shape)\n",
        "# print(\"Quantum feature size（Val）:\", X_val_quanv.shape)\n",
        "# print(\"Quantum feature size（Test）:\", X_test_quanv.shape)\n"
      ],
      "metadata": {
        "id": "iftUVz-IwzYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "# def compute_kernel_matrix(X):\n",
        "#     \"\"\"\n",
        "#     Compute Quantum Kernel Matrix\n",
        "#     - X: quantum eigenvector (N, d), where N is the number of samples and d is the number of features\n",
        "#     - returns the Kernel matrix of (N, N)\n",
        "#     \"\"\"\n",
        "#     N = len(X)\n",
        "#     kernel_matrix = np.zeros((N, N))\n",
        "\n",
        "#     for i in range(N):\n",
        "#         for j in range(i, N):  # 只計算上三角矩陣（因為對稱）\n",
        "#             kernel_matrix[i, j] = np.dot(X[i], X[j])  # 內積當作 Kernel\n",
        "#             kernel_matrix[j, i] = kernel_matrix[i, j]  # 利用對稱性\n",
        "\n",
        "#     return kernel_matrix"
      ],
      "metadata": {
        "id": "58ja_fa5Dv9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rbf kernel\n",
        "\n",
        "# def compute_kernel_matrix(X, gamma=0.5):\n",
        "#     N = len(X)\n",
        "#     kernel_matrix = np.zeros((N, N))\n",
        "\n",
        "#     for i in range(N):\n",
        "#         for j in range(i, N):\n",
        "#             dist = np.linalg.norm(X[i] - X[j]) ** 2\n",
        "#             kernel_matrix[i, j] = np.exp(-gamma * dist)  # Gaussian Kernel\n",
        "#             kernel_matrix[j, i] = kernel_matrix[i, j]\n",
        "\n",
        "#     return kernel_matrix"
      ],
      "metadata": {
        "id": "-yeGsvXwI5I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantum Kernel Matrix\n",
        "# train_kernel_matrix = compute_kernel_matrix(X_train_quanv)\n",
        "# val_kernel_matrix = np.array([[np.dot(x1, x2) for x2 in X_train_quanv] for x1 in X_val_quanv])\n",
        "# test_kernel_matrix = np.array([[np.dot(x1, x2) for x2 in X_train_quanv] for x1 in X_test_quanv])\n",
        "\n",
        "# print(\"Train Kernel Matrix:\", train_kernel_matrix.shape)  # (N_train, N_train)\n",
        "# print(\"Val Kernel Matrix:\", val_kernel_matrix.shape)      # (N_val, N_train)\n",
        "# print(\"Test Kernel Matrix:\", test_kernel_matrix.shape)    # (N_test, N_train)"
      ],
      "metadata": {
        "id": "z96gGP0KxBqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn import svm\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# # train Quantum SVM\n",
        "# qsvm = svm.SVC(kernel=\"precomputed\")\n",
        "# qsvm.fit(train_kernel_matrix, y_train)\n"
      ],
      "metadata": {
        "id": "0smAhdcPxCuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # test  QSVM in val set\n",
        "# preds_val = qsvm.predict(val_kernel_matrix)\n",
        "# accuracy_val = accuracy_score(y_val, preds_val)\n",
        "# print(f\"QSVM Validation Accuracy: {accuracy_val:.4f}\")\n",
        "\n",
        "# # test QSVM in test set\n",
        "# preds_test = qsvm.predict(test_kernel_matrix)\n",
        "# accuracy_test = accuracy_score(y_test, preds_test)\n",
        "# print(f\"QSVM Test Accuracy: {accuracy_test:.4f}\")\n"
      ],
      "metadata": {
        "id": "SeQ00cyhxKVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose label=0&1\n",
        "X_train_0 = X_train[y_train == 0]\n",
        "y_train_0 = y_train[y_train == 0]\n",
        "\n",
        "X_train_1 = X_train[y_train == 1]\n",
        "y_train_1 = y_train[y_train == 1]\n",
        "\n",
        "X_val_0 = X_val[y_val == 0]\n",
        "y_val_0 = y_val[y_val == 0]\n",
        "\n",
        "X_val_1 = X_val[y_val == 1]\n",
        "y_val_1 = y_val[y_val == 1]\n",
        "\n",
        "X_test_0 = X_test[y_test == 0]\n",
        "y_test_0 = y_test[y_test == 0]\n",
        "\n",
        "X_test_1 = X_test[y_test == 1]\n",
        "y_test_1 = y_test[y_test == 1]\n",
        "\n",
        "print(f\"label=0 訓練數據數量: {X_train_0.shape}\")\n",
        "print(f\"label=0 訓練數據數量: {X_val_0.shape}\")\n",
        "print(f\"label=0 訓練數據數量: {X_test_0.shape}\")\n",
        "\n",
        "print(f\"訓練資料 label=1 數量: {X_train_1.shape}\")\n",
        "print(f\"驗證資料 label=1 數量: {X_val_1.shape}\")\n",
        "print(f\"測試資料 label=1 數量: {X_test_1.shape}\")\n"
      ],
      "metadata": {
        "id": "gdAmEmfJKFkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_0 = np.array([quanvolution(img) for img in X_train_0])\n",
        "X_val_0 = np.array([quanvolution(img) for img in X_val_0])\n",
        "X_test_0 = np.array([quanvolution(img) for img in X_test_0])\n",
        "\n",
        "print(\" X_train_0 shape:\", X_train_0.shape)  # (84, 特徵數)\n",
        "print(\" X_val_0 shape:\", X_val_0.shape)      # (88, 特徵數)\n",
        "print(\"X_test_0 shape:\", X_test_0.shape)    # (79, 特徵數)"
      ],
      "metadata": {
        "id": "CSJERG6FPdwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_1 = np.array([quanvolution(img) for img in X_train_1])\n",
        "X_val_1 = np.array([quanvolution(img) for img in X_val_1])\n",
        "X_test_1 = np.array([quanvolution(img) for img in X_test_1])\n",
        "\n",
        "print(\" X_train_1 shape:\", X_train_1.shape)  # (84, 特徵數)\n",
        "print(\" X_val_1 shape:\", X_val_1.shape)      # (82, 特徵數)\n",
        "print(\"X_test_1 shape:\", X_test_1.shape)    # (84, 特徵數)"
      ],
      "metadata": {
        "id": "Er6zzd8gLKDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 合併 label=0 和 label=1 的量子特徵數據\n",
        "X_train_01 = np.vstack([X_train_0, X_train_1])\n",
        "y_train_01 = np.hstack([y_train_0, y_train_1])\n",
        "\n",
        "print(f\"合併後的訓練數據: {X_train_01.shape}\")\n",
        "print(f\"合併後的標籤數據: {y_train_01.shape}\")\n",
        "\n",
        "X_val_01 = np.vstack([X_val_0, X_val_1])\n",
        "y_val_01 = np.hstack([y_val_0, y_val_1])\n",
        "\n",
        "print(f\"合併後的訓練數據: {X_val_01.shape}\")\n",
        "print(f\"合併後的標籤數據: {y_val_01.shape}\")\n",
        "\n",
        "X_test_01 = np.vstack([X_test_0, X_test_1])\n",
        "y_test_01 = np.hstack([y_test_0, y_test_1])\n",
        "\n",
        "print(f\"合併後的訓練數據: {X_test_01.shape}\")\n",
        "print(f\"合併後的標籤數據: {y_test_01.shape}\")"
      ],
      "metadata": {
        "id": "Mmyc2JbFU8i-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "# 先把影像攤平成 2D 數據 (N, 4096)\n",
        "X_train_flat = X_train_01.reshape(X_train_01.shape[0], -1)\n",
        "X_val_flat = X_val_01.reshape(X_val_01.shape[0], -1)\n",
        "X_test_flat = X_test_01.reshape(X_test_01.shape[0], -1)\n",
        "\n",
        "# 使用 PCA 降維\n",
        "pca = PCA(n_components=16)\n",
        "X_train_pca = pca.fit_transform(X_train_flat)\n",
        "X_val_pca = pca.fit_transform(X_val_flat)\n",
        "X_test_pca = pca.fit_transform(X_test_flat)\n",
        "\n",
        "print(\"降維後的數據形狀：\", X_train_pca.shape)  # (N, 4)\n",
        "print(\"降維後的數據形狀：\", X_val_pca.shape)  # (N, 4)\n"
      ],
      "metadata": {
        "id": "2rQIR6GrgV9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pennylane as qml\n",
        "# import pennylane.numpy as np\n",
        "\n",
        "# n_qubits = 4\n",
        "# dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "# @qml.qnode(dev)\n",
        "# def feature_map(x):\n",
        "#     # 將輸入 x（維度 4 的向量）嵌入到量子態中\n",
        "#     qml.AngleEmbedding(x, wires=range(n_qubits))\n",
        "#     # 回傳每個 qubit 上 Pauli-Z 的期望值，形成一個 4 維向量\n",
        "#     return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n"
      ],
      "metadata": {
        "id": "gDf0gJ2PTUIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def quantum_kernel_fidelity(x1, x2):\n",
        "#     phi1 = np.array(feature_map(x1))\n",
        "#     phi2 = np.array(feature_map(x2))\n",
        "#     # 使用內積的平方作為核值\n",
        "#     return np.dot(phi1, phi2)**2"
      ],
      "metadata": {
        "id": "5bNUdq2OUZTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def compute_quantum_kernel_matrix(X, kernel_func=quantum_kernel_fidelity):\n",
        "#     N = len(X)\n",
        "#     K = np.zeros((N, N))\n",
        "#     for i in range(N):\n",
        "#         for j in range(i, N):\n",
        "#             K[i, j] = kernel_func(X[i], X[j])\n",
        "#             K[j, i] = K[i, j]\n",
        "#     return K"
      ],
      "metadata": {
        "id": "9HHmEMG0hXt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "import pennylane.numpy as np  # PennyLane 版本的 numpy\n",
        "import numpy as onp          # 傳統 NumPy，避免混淆時可用 \"onp\"\n",
        "\n",
        "n_qubits = 16\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def feature_map(x):\n",
        "    \"\"\"\n",
        "    將輸入 x (長度 <= n_qubits) 嵌入到量子態中，\n",
        "    回傳每個 qubit 上 PauliZ 的期望值，形成一個長度 = n_qubits 的向量。\n",
        "    \"\"\"\n",
        "    qml.AngleEmbedding(x, wires=range(n_qubits))\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
        "\n",
        "def quantum_kernel_fidelity(x1, x2):\n",
        "    \"\"\"\n",
        "    量子核函數：先透過 feature_map() 得到兩個量子特徵向量 phi1, phi2，\n",
        "    然後取內積 (dot) 再平方，作為「類似保真度」的核值。\n",
        "    \"\"\"\n",
        "    # feature_map(x) 回傳的是一個可微的 list[ArrayBox, ...]\n",
        "    # 用 qml.math.stack() 把它變成同一個張量\n",
        "    # phi1 = qml.math.stack(feature_map(x1))\n",
        "    # phi2 = qml.math.stack(feature_map(x2))\n",
        "\n",
        "    # 內積 (dot) → dot**2\n",
        "    # dot_value = qml.math.dot(phi1, phi2)\n",
        "    # kernel_val = dot_value**2\n",
        "\n",
        "\n",
        "    # 有時需要轉成 Python float 或 onp.float64 才能塞到 Kernel Matrix\n",
        "    # 這裡用 qml.math.toarray() 轉成可用的數值\n",
        "    # return qml.math.toarray(kernel_val)\n",
        "\n",
        "    #使用內稽平方作為核值\n",
        "    phi1 = np.array(feature_map(x1))\n",
        "    phi2 = np.array(feature_map(x2))\n",
        "    return np.dot(phi1, phi2) ** 2\n",
        "\n",
        "\n",
        "def compute_quantum_kernel_matrix(X1, X2, kernel_func=quantum_kernel_fidelity):\n",
        "    N1 = len(X1)\n",
        "    N2 = len(X2)\n",
        "    K = onp.zeros((N1, N2))\n",
        "    for i in range(N1):\n",
        "        for j in range(N2):\n",
        "            # 這裡要呼叫 kernel_func(X1[i], X2[j]) 兩個參數\n",
        "            K[i, j] = kernel_func(X1[i], X2[j])\n",
        "    return K"
      ],
      "metadata": {
        "id": "-HmwWcwhhjKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 假設 X_train.shape = (N_train, d)，y_train.shape = (N_train,)\n",
        "K_train= compute_quantum_kernel_matrix(X_train_pca, X_train_pca, quantum_kernel_fidelity)\n",
        "K_val= compute_quantum_kernel_matrix(X_val_pca, X_train_pca, quantum_kernel_fidelity)\n",
        "K_test= compute_quantum_kernel_matrix(X_test_pca, X_train_pca, quantum_kernel_fidelity)\n",
        "\n",
        "print(f\"Train Kernel Matrix: {K_train.shape}\")\n",
        "print(f\"Val Kernel Matrix: {K_val.shape}\")\n",
        "print(f\"Test Kernel Matrix: {K_test.shape}\")"
      ],
      "metadata": {
        "id": "nchbG-AB1XCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用 precomputed kernel 的 SVM\n",
        "qsvm = svm.SVC(kernel=\"precomputed\")\n",
        "qsvm.fit(K_train, y_train_01)\n",
        "\n",
        "# 驗證\n",
        "val_preds = qsvm.predict(K_val)\n",
        "val_acc   = accuracy_score(y_val_01, val_preds)\n",
        "print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
        "\n",
        "# 測試\n",
        "test_preds = qsvm.predict(K_test )\n",
        "test_acc = accuracy_score(y_test_01, test_preds)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "Lj-HOU021hvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K_train = compute_quantum_kernel_matrix(X_train_pca)\n",
        "# K_val = compute_quantum_kernel_matrix(X_val_pca)\n",
        "# K_test = compute_quantum_kernel_matrix(X_test_pca)\n",
        "\n"
      ],
      "metadata": {
        "id": "-6uv51HNhc_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn import svm\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# qsvm = svm.SVC(kernel=\"precomputed\")\n",
        "# qsvm.fit(K_train, y_train_01)\n",
        "\n",
        "# val_preds = qsvm.predict(K_val)\n",
        "# test_preds = qsvm.predict(K_test)\n",
        "\n",
        "# val_acc = accuracy_score(y_val_01, val_preds)\n",
        "# test_acc = accuracy_score(y_test_01, test_preds)\n",
        "\n",
        "# print(f\"QSVM Validation Accuracy: {val_acc:.4f}\")\n",
        "# print(f\"QSVM Test Accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "RCg6JYqEkGXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train shape:\", X_train_pca.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_val shape:\", X_val_pca.shape)\n",
        "print(\"y_val shape:\", y_val.shape)\n"
      ],
      "metadata": {
        "id": "5800BeRMr3UM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"train_kernel_matrix shape:\", K_train.shape)\n",
        "print(\"val_kernel_matrix shape:\", K_val.shape)\n"
      ],
      "metadata": {
        "id": "YvwQK53tsDA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 計算 Kernel Matrix（只使用 label=1 的數據）\n",
        "# train_kernel_matrix_01 = compute_kernel_matrix(X_train_01)\n",
        "# val_kernel_matrix_01 = np.array([[np.dot(x1, x2) for x2 in X_train_01] for x1 in X_val_01])\n",
        "# test_kernel_matrix_01 = np.array([[np.dot(x1, x2) for x2 in X_train_01] for x1 in X_test_01])\n",
        "\n",
        "# print(f\"Train Kernel Matrix (label=1): {train_kernel_matrix_01.shape}\")\n",
        "# print(f\"Val Kernel Matrix (label=1): {val_kernel_matrix_01.shape}\")\n",
        "# print(f\"Test Kernel Matrix (label=1): {test_kernel_matrix_01.shape}\")"
      ],
      "metadata": {
        "id": "JwNB2hnRKOWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 訓練 Quantum SVM\n",
        "qsvm = svm.SVC(kernel=\"precomputed\")\n",
        "qsvm.fit(train_kernel_matrix_01, y_train_01)\n",
        "\n",
        "# 測試 QSVM 在驗證集\n",
        "preds_val_1 = qsvm.predict(val_kernel_matrix_01)\n",
        "accuracy_val_1 = accuracy_score(y_val_01, preds_val_1)\n",
        "print(f\"QSVM Validation Accuracy (label=01): {accuracy_val_1:.4f}\")\n",
        "\n",
        "# 測試 QSVM 在測試集\n",
        "preds_test_1 = qsvm.predict(test_kernel_matrix_01)\n",
        "accuracy_test_1 = accuracy_score(y_test_01, preds_test_1)\n",
        "print(f\"QSVM Test Accuracy (label=01): {accuracy_test_1:.4f}\")"
      ],
      "metadata": {
        "id": "Cf6wM4_xKUXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 傳統 SVM（使用 RBF 核）\n",
        "classical_svm = svm.SVC(kernel=\"linear\")\n",
        "classical_svm.fit(X_train_01, y_train_01)\n",
        "preds_classical = classical_svm.predict(X_test_01)\n",
        "val_preds_classical = classical_svm.predict(X_val_01)\n",
        "acc_classical = accuracy_score(y_test_01, preds_classical)\n",
        "val_classical = accuracy_score(y_val_01, val_preds_classical)\n",
        "\n",
        "print(f\"Classical SVM Accuracy: {val_classical:.4f}\")\n",
        "print(f\"Classical SVM Accuracy: {acc_classical:.4f}\")"
      ],
      "metadata": {
        "id": "xUn2hVvtc_Ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KmdA0V5JdhF3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}